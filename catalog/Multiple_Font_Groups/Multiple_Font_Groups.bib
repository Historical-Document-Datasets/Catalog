@inproceedings{10.1145/3352631.3352640,
    author = "Seuret, Mathias and Limbach, Saskia and Weichselbaumer, Nikolaus and Maier, Andreas and Christlein, Vincent",
    title = "Dataset of {P}ages from {E}arly {P}rinted {B}ooks with {M}ultiple {F}ont {G}roups",
    year = "2019",
    isbn = "9781450376686",
    publisher = "Association for Computing Machinery",
    address = "New York, NY, USA",
    doi = "10.1145/3352631.3352640",
    abstract = "Based on contemporary scripts, early printers developed a large variety of different fonts. While fonts may slightly differ from one printer to another, they can be divided into font groups, such as Textura, Antiqua, or Fraktur. The recognition of font groups is important for computer scientists to select adequate OCR models, and of high interest to humanities scholars studying early printed books and the history of fonts. In this paper, we introduce a new, public dataset for the recognition of font groups in early printed books, and evaluate several state-of-the-art CNNs for the font group recognition task. The dataset consists of more than 35 600 page images, each page showing up to five different font groups, of which ten are considered in this dataset.",
    booktitle = "Proceedings of the 5th International Workshop on Historical Document Imaging and Processing",
    pages = "1â€“6",
    numpages = "6",
    keywords = "Schwabacher, Italic, historical documents, Fraktur, book history, incunabula, Greek, type, document analysis, typography, fonts, Antiqua, Textura, digital humanities, Rotunda, Bastarda, Gotico-Antiqua, dataset, neural network, Hebrew",
    location = "Sydney, NSW, Australia",
    series = "HIP '19"
}

@article{He2016DeepRL,
    author = "He, Kaiming and Zhang, X. and Ren, Shaoqing and Sun, Jian",
    title = "{Deep Residual Learning for Image Recognition}",
    journal = "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
    year = "2016",
    pages = "770-778"
}

@article{Simonyan2015VeryDC,
    author = "Simonyan, Karen and Zisserman, Andrew",
    title = "Very {Deep Convolutional Networks for Large-Scale Image Recognition}",
    journal = "CoRR",
    year = "2015",
    volume = "abs/1409.1556"
}

@article{huang2018densely,
    author = "Huang, Gao and Liu, Zhuang and Weinberger, Kilian Q.",
    title = "{Densely Connected Convolutional Networks}",
    journal = "2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
    year = "2017",
    pages = "2261-2269"
}

@InProceedings{10.1007/978-3-030-86337-1_41,
    author = "Seuret, Mathias and Nicolaou, Anguelos and Rodr{\'i}guez-Salas, Dalia and Weichselbaumer, Nikolaus and Stutzmann, Dominique and Mayr, Martin and Maier, Andreas and Christlein, Vincent",
    editor = "Llad{\'o}s, Josep and Lopresti, Daniel and Uchida, Seiichi",
    title = "{ICDAR} 2021 {Competition} on {H}istorical {Document} {Classification}",
    booktitle = "Document Analysis and Recognition -- ICDAR 2021",
    year = "2021",
    publisher = "Springer International Publishing",
    address = "Cham",
    pages = "618--634",
    abstract = "This competition investigated the performance of historical document classification. The analysis of historical documents is a difficult challenge commonly solved by trained humanists. We provided three different classification tasks, which can be solved individually or jointly: font group/script type, location, date. The document images are provided by several institutions and are taken from handwritten and printed books as well as from charters. In contrast to previous competitions, all participants relied upon Deep Learning based approaches. Nevertheless, we saw a great performance variety of the different submitted systems. The easiest task seemed to be font group recognition while the script type classification and location classification were more challenging. In the dating task, the best system achieved a mean absolute error of about 22 years.",
    isbn = "978-3-030-86337-1"
}
